{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ekonlpy.sentiment import MPCK\n",
    "\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import pickle\n",
    "\n",
    "import os, sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ekonlpy\n",
    "# python ver 3.8.1 이상 3.12 이하에서만 받을 수 있다고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ekonlpy import Mecab\n",
    "from ekonlpy.sentiment.utils import KTokenizer\n",
    "\n",
    "# 명사(NNG), 형용사(VA, VAX), 부사(MAG), 동사(VA)\n",
    "text = '금통위는 따라서 물가안정과 병행, 경기상황에 유의하는 금리정책을 펼쳐나가기로 했다고 밝혔다.'\n",
    "mecab = Mecab()\n",
    "\n",
    "tokens = mecab.tokenize(text)\n",
    "print(tokens)\n",
    "ktt = KTokenizer()\n",
    "ktt._ngram = 5\n",
    "ktt.ngramize(tokens)\n",
    "# ktt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from ekonlpy import Mecab\n",
    "from ekonlpy.sentiment.utils import KTokenizer\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(path, filename))\n",
    "        mecab = Mecab()\n",
    "        tokens = mecab.tokenize(df)\n",
    "        print(tokens)\n",
    "        ktt = KTokenizer()\n",
    "        ktt._ngram = 5\n",
    "        ktt.ngramize(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<앵커>이렇게 극도로 침체된 부동산시장, 앞으론 어떨까요? 경제부에서 부동산 취재하는 심 기자, 무엇보다 집이 없이 세입자로 사는 분들이 큰 걱정인데, 이렇게 거래가 끊기면 전셋값도 오른다 그렇게 봐야겠죠?<기자>물론입니다. 현재 매매가 대비 전세가 비율이 55%에 달하는 역대 최고 수준입니다. 집을 살 수 있는데 전세로 눌러 않는 사람이 많아서 전세금은 계속 오르고 있는 겁니다.그럼 서민들은 오른 전세금만큼 월세로 내는 반전세로 계약하거나 결국 외곽으로 쫓겨나는 답답한 상황에 놓이게 되는 겁니다.<앵커>앞으로 집값은 어떻게 될까요? 심 기자라면 올해 집을 사겠습니까?<기자>저도 실거주를 목적으로 하는 만큼 당장은 아니어도 올해 안에 집을 사는 쪽으로 조심스레 생각해보고 있습니다.먼저 말씀드린 높은 전세금 부담이 있고요. 또 저금리 같은 환경이 주어진데다 새 정부의 규제 완화도 기대할 만 하겠죠. 또 장기간 조정을 거친 현재의 가격, 여기에 금리 정책이라는 세 가지 변수가 집값 바닥론을 뒷받침하고 있습니다. 그렇게 때문에 시세보다 싼 급매물을 중심으로 접근해 볼만 하다고 생각합니다.다만 실물경기 회복속도가 더디고 장기 침체의 위험도 여전한 만큼 크게 오를 것을 기대하는 것은 절대 금물이겠죠.    심우섭 관/련/정/보◆ '범서방파' 김태촌 사망…파란만장했던 삶◆ \"박 당선인, 다보스포럼에 이인제 특사 파견\"◆  제왕절개 중 의사 손가락 잡은 아기◆ '피겨퀸' 김연아 곧 출격! 미리 본 명품 연기◆  '차 밀기 귀찮아'…황당한 주차 포착☞ ☞ SBS뉴스 공식 SNS    저작권자 SBS&SBS콘텐츠허브 무단복제-재배포 금지\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "encoding without a string argument",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m mecab \u001b[39m=\u001b[39m Mecab()\n\u001b[0;32m     15\u001b[0m \u001b[39m# 각 텍스트 데이터에 대해 형태소 분석 및 토큰화 수행\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m tokens_list \u001b[39m=\u001b[39m [mecab\u001b[39m.\u001b[39mpos(text) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m texts]\n\u001b[0;32m     18\u001b[0m \u001b[39mprint\u001b[39m(tokens_list)\n",
      "Cell \u001b[1;32mIn[9], line 16\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     13\u001b[0m mecab \u001b[39m=\u001b[39m Mecab()\n\u001b[0;32m     15\u001b[0m \u001b[39m# 각 텍스트 데이터에 대해 형태소 분석 및 토큰화 수행\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m tokens_list \u001b[39m=\u001b[39m [mecab\u001b[39m.\u001b[39;49mpos(text) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m texts]\n\u001b[0;32m     18\u001b[0m \u001b[39mprint\u001b[39m(tokens_list)\n",
      "File \u001b[1;32mc:\\Users\\lonec\\anaconda3\\lib\\site-packages\\ekonlpy\\tag\\_mecab.py:172\u001b[0m, in \u001b[0;36mMecab.pos\u001b[1;34m(self, text, flatten, include_whitespace_token)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpos\u001b[39m(\n\u001b[0;32m    167\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    168\u001b[0m     text: \u001b[39mstr\u001b[39m,\n\u001b[0;32m    169\u001b[0m     flatten: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    170\u001b[0m     include_whitespace_token: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    171\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Tuple[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]]:\n\u001b[1;32m--> 172\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse(text, flatten, include_whitespace_token)\n",
      "File \u001b[1;32mc:\\Users\\lonec\\anaconda3\\lib\\site-packages\\ekonlpy\\tag\\_mecab.py:163\u001b[0m, in \u001b[0;36mMecab.parse\u001b[1;34m(self, text, flatten, include_whitespace_token)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse\u001b[39m(\n\u001b[0;32m    158\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    159\u001b[0m     text: \u001b[39mstr\u001b[39m,\n\u001b[0;32m    160\u001b[0m     flatten: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    161\u001b[0m     include_whitespace_token: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    162\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Tuple[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]]:\n\u001b[1;32m--> 163\u001b[0m     tagged \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mparse(text, flatten, include_whitespace_token)\n\u001b[0;32m    164\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extagger\u001b[39m.\u001b[39mpos(tagged) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extagger \u001b[39melse\u001b[39;00m tagged\n",
      "File \u001b[1;32mc:\\Users\\lonec\\anaconda3\\lib\\site-packages\\ekonlpy\\mecab\\_mecab.py:116\u001b[0m, in \u001b[0;36mMecab.parse\u001b[1;34m(self, text, flatten, include_whitespace_token)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse\u001b[39m(\n\u001b[0;32m    110\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    111\u001b[0m     text: \u001b[39mstr\u001b[39m,\n\u001b[0;32m    112\u001b[0m     flatten: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    113\u001b[0m     include_whitespace_token: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    114\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Tuple[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]]:\n\u001b[0;32m    115\u001b[0m     \u001b[39mif\u001b[39;00m flatten:\n\u001b[1;32m--> 116\u001b[0m         res \u001b[39m=\u001b[39m [(surface, feature\u001b[39m.\u001b[39mpos) \u001b[39mfor\u001b[39;00m surface, feature \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse(text)]\n\u001b[0;32m    117\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m         res \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\lonec\\anaconda3\\lib\\site-packages\\ekonlpy\\mecab\\_mecab.py:106\u001b[0m, in \u001b[0;36mMecab._parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_parse\u001b[39m(\u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Tuple[\u001b[39mstr\u001b[39m, Feature]]:\n\u001b[0;32m    104\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m    105\u001b[0m         (node\u001b[39m.\u001b[39msurface, _extract_feature(node\u001b[39m.\u001b[39mfeature))\n\u001b[1;32m--> 106\u001b[0m         \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tagger(text)\n\u001b[0;32m    107\u001b[0m     ]\n",
      "File \u001b[1;32mfugashi\\fugashi.pyx:239\u001b[0m, in \u001b[0;36mfugashi.fugashi.GenericTagger.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mfugashi\\fugashi.pyx:255\u001b[0m, in \u001b[0;36mfugashi.fugashi.GenericTagger.parseToNodeList\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: encoding without a string argument"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m input_dir \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./secret_news_cleanse\u001b[39m\u001b[39m'\u001b[39m  \n\u001b[0;32m     29\u001b[0m output_dir \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./secret_tokenization\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 30\u001b[0m process_and_save_csv(input_dir, output_dir)\n",
      "Cell \u001b[1;32mIn[12], line 21\u001b[0m, in \u001b[0;36mprocess_and_save_csv\u001b[1;34m(input_dir, output_dir)\u001b[0m\n\u001b[0;32m     18\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(input_dir, filename))\n\u001b[0;32m     20\u001b[0m \u001b[39m# '내용' 열에서 형태소 분석 및 토큰화 수행\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mtokenized_content\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39m내용\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(tokenize_if_str)\n\u001b[0;32m     23\u001b[0m \u001b[39m# 결과를 새로운 파일로 저장\u001b[39;00m\n\u001b[0;32m     24\u001b[0m save_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_dir, filename)\n",
      "File \u001b[1;32mc:\\Users\\lonec\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\lonec\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\lonec\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1175\u001b[0m             values,\n\u001b[0;32m   1176\u001b[0m             f,\n\u001b[0;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1178\u001b[0m         )\n\u001b[0;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\lonec\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m, in \u001b[0;36mtokenize_if_str\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, \u001b[39mstr\u001b[39m):\n\u001b[1;32m----> 8\u001b[0m         mecab \u001b[39m=\u001b[39m Mecab()\n\u001b[0;32m      9\u001b[0m         \u001b[39mreturn\u001b[39;00m mecab\u001b[39m.\u001b[39mpos(text)\n\u001b[0;32m     10\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\lonec\\anaconda3\\lib\\site-packages\\ekonlpy\\tag\\_mecab.py:50\u001b[0m, in \u001b[0;36mMecab.__init__\u001b[1;34m(self, use_default_dictionary, use_polarity_phrase, use_original_tagger, dicdir, userdic_path, verbose, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m     41\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     42\u001b[0m     use_default_dictionary: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m     49\u001b[0m ):\n\u001b[1;32m---> 50\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(dicdir, userdic_path, verbose, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_default_dictionary \u001b[39m=\u001b[39m use_default_dictionary\n\u001b[0;32m     52\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_polarity_phras \u001b[39m=\u001b[39m use_polarity_phrase\n",
      "File \u001b[1;32mc:\\Users\\lonec\\anaconda3\\lib\\site-packages\\ekonlpy\\mecab\\_mecab.py:89\u001b[0m, in \u001b[0;36mMecab.__init__\u001b[1;34m(self, dicdir, userdic_path, verbose, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     88\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tagger \u001b[39m=\u001b[39m _mecab\u001b[39m.\u001b[39mGenericTagger(MECAB_ARGS)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[0;32m     90\u001b[0m         dictionary_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tagger\u001b[39m.\u001b[39mdictionary_info\n\u001b[0;32m     91\u001b[0m         sysdic_path \u001b[39m=\u001b[39m dictionary_info[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from ekonlpy import Mecab\n",
    "\n",
    "def tokenize_if_str(text):\n",
    "    try:\n",
    "        if isinstance(text, str):\n",
    "            mecab = Mecab()\n",
    "            return mecab.pos(text)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "def process_and_save_csv(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.csv'):\n",
    "            df = pd.read_csv(os.path.join(input_dir, filename))\n",
    "            \n",
    "            df['tokenized_content'] = df['내용'].apply(tokenize_if_str)\n",
    "            \n",
    "            save_path = os.path.join(output_dir, filename)\n",
    "            df.to_csv(save_path, encoding='utf-8', index=False)\n",
    "\n",
    "\n",
    "input_dir = './secret_news_cleanse'  \n",
    "output_dir = './secret_tokenization'\n",
    "process_and_save_csv(input_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mecab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
