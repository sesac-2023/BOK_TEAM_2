{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "# 의사록(MPB)\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "for i in range(1, 45):\n",
    "    b_url = \"https://www.bok.or.kr/portal/bbs/B0000245/list.do?menuNo=200761\"\n",
    "    params = {\n",
    "        'pageIndex' : i\n",
    "    }\n",
    "\n",
    "    response = requests.get(b_url, params=params)\n",
    "    soup = BeautifulSoup(response.content)\n",
    "\n",
    "    li_list = []\n",
    "    li = soup.find('div', class_='bdLine type2').find('ul').find('li')\n",
    "    li_li = li.find_next_siblings('li', li)\n",
    "    li_list.append(li)\n",
    "    li_list.extend(li_li)\n",
    "\n",
    "    print(i)\n",
    "\n",
    "    for x in range(0, len(li_list)):\n",
    "        try:\n",
    "            link = li_list[x].find('div', class_='fileGoupBox').find('ul').find('li').find('a').attrs['href']\n",
    "            title = li_list[x].find('div', class_='row').find('span').find('a').find('span').find('span').text\n",
    "            url2 = 'http://www.bok.or.kr' + link\n",
    "            file_res = requests.get(url2)\n",
    "\n",
    "            with open('{}.hwp'.format(title), 'wb') as f:\n",
    "                f.write(file_res.content)\n",
    "        except:\n",
    "            link2 = li_list[x].find('div').find('div').find('a').attrs['href']\n",
    "            title = li_list[x].find('div', class_='row').find('span').find('a').find('span').find('span').text\n",
    "            url3 = 'http://www.bok.or.kr' + link2\n",
    "            file_res2 = requests.get(url3)\n",
    "\n",
    "            with open('{}.hwp'.format(title), 'wb') as f:\n",
    "                f.write(file_res.content)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "통과\n",
      "통과\n"
     ]
    }
   ],
   "source": [
    "# 채권 분석 리포트 https://finance.naver.com/research/debenture_list.naver\n",
    "import time\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "for i in range (1, 198):\n",
    "    bond_url = \"https://finance.naver.com/research/debenture_list.naver\"\n",
    "    params = {\n",
    "        'page' : i\n",
    "    }\n",
    "    headers = {'authority' : 'finance.naver.com',\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36' }\n",
    "   \n",
    "\n",
    "    response = requests.get(bond_url, params=params, headers=headers)\n",
    "    soup = BeautifulSoup(response.content)\n",
    "    bond = soup.select('#contentarea_left .file')\n",
    "    bond_list = []\n",
    "    for x in range(len(bond)):\n",
    "        if bond[x].find_previous_sibling('td').text == '유안타증권':\n",
    "            try:    \n",
    "                bond_list.append([soup.select(\"#contentarea_left .file a[href$='.pdf']\")[x].attrs['href'], bond[x].find_previous_sibling('td').find_previous_sibling('td').text])\n",
    "            except:\n",
    "                print(\"통과\")\n",
    "\n",
    "    for y in bond_list:\n",
    "        file_res = requests.get(y[0])\n",
    "        title = y[-1]\n",
    "        try:\n",
    "            with open('{}.pdf'.format(title), 'wb') as f:\n",
    "                f.write(file_res.content)\n",
    "        except:\n",
    "            print('통과')\n",
    "\n",
    "\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 월별 기사수 '금리'라는 단어 포함\n",
    "2. 각 신문사별 기사수\n",
    "3. 채권분석데이터수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/130 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [03:52<00:00,  5.41s/it]\n",
      "  1%|          | 1/130 [03:53<8:21:09, 233.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [05:50<00:00,  4.44s/it]\n",
      "  2%|▏         | 2/130 [09:44<10:45:30, 302.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://finance.naver.com/news/news_read.naver?article_id=0000027614&office_id=050&mode=search&query=금리&page=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# NNC(NaverNewsCrawling)\n",
    "import time\n",
    "import datetime\n",
    "import requests, os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "date_date = pd.date_range('2012-12-30', '2023-08-31', freq='W') #2013년부터 2023년까지 뉴스데이터 크롤링\n",
    "date_role = [date_date[:130],date_date[130:260],date_date[260:390],date_date[390:520],date_date[520:]]\n",
    "df = pd.DataFrame(columns =['신문사', '제목', '내용', '날짜'])\n",
    "\n",
    "for date in tqdm(date_role[0]):  #자신의 번호로 인덱싱\n",
    "    DateStart = date.strftime('%Y-%m-%d')\n",
    "    DateEnd = (date+datetime.timedelta(6)).strftime('%Y-%m-%d')\n",
    "    last_url = f\"https://finance.naver.com/news/news_search.naver?rcdate=&q=%B1%DD%B8%AE&x=20&y=14&sm=all.basic&pd=4&stDateStart={DateStart}&stDateEnd={DateEnd}&page=1\"\n",
    "    headers = {'authority' : 'finance.naver.com',\n",
    "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'}\n",
    "    response = requests.get(last_url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content)\n",
    "    last_page = soup.select('.pgRR a')[0]['href'].split('=')[-1] #마지막 페이지 가져오기\n",
    "    print(last_page)\n",
    "    for i in tqdm(range(1, int(last_page)+1)):   # 여기서 마지막 페이지까지 반복문\n",
    "        news_url = f\"https://finance.naver.com/news/news_search.naver?rcdate=&q=%B1%DD%B8%AE&x=20&y=14&sm=all.basic&pd=4&stDateStart={DateStart}&stDateEnd={DateEnd}&page={i}\"\n",
    "        headers = {'authority' : 'finance.naver.com',\n",
    "                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'}\n",
    "        response = requests.get(news_url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content)\n",
    "        news = soup.select('.thumb a' )\n",
    "        magazine = soup.select('.articleSummary .press') #신문사 데이터\n",
    "        newsdate = soup.select('.articleSummary .wdate') # 날짜 데이터\n",
    "\n",
    "        news_link = []\n",
    "        magazine_name = []\n",
    "        dates = []\n",
    "        for i in range(len(news)):\n",
    "            news_link.append('https://finance.naver.com' + news[i].attrs['href'].replace('amp;', ''))  #amp;제거해서 링크활성화\n",
    "            magazine_name.append(magazine[i].text)\n",
    "            dates.append(newsdate[i])\n",
    "\n",
    "        total = []\n",
    "        for index, j in enumerate(news_link):\n",
    "            news_resp = requests.get(j, headers=headers)\n",
    "            news_soup = BeautifulSoup(news_resp.content)\n",
    "            try:\n",
    "                title = news_soup.select('.article_info h3')[0].text.strip()\n",
    "                content = news_soup.select('#content')[-1].text.strip()\n",
    "            except:\n",
    "                print(j)\n",
    "                continue\n",
    "            total.append([magazine_name[index],title, content, newsdate[index].text.lstrip()[:10]])\n",
    "        \n",
    "        df_temp = pd.DataFrame(total, columns = ['신문사', '제목', '내용', '날짜'])  #모든 리스트를 데이터프레임으로 전환\n",
    "        df = pd.concat([df, df_temp], ignore_index = True)\n",
    "    df.to_csv(f'{DateStart}_{DateEnd}.csv', encoding='utf-8') # 1주일 간격으로 크롤링 데이터 저장    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/556 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'DatetimeIndex' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m last_page \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pgRR a\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;66;03m# =기준 split으로 수정\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(last_page)\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlast_page\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m):   \u001b[38;5;66;03m# 여기서 다양한 최종페이지까지 설정\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     news_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://finance.naver.com/news/news_search.naver?rcdate=&q=%B1%DD%B8%AE&x=20&y=14&sm=all.basic&pd=4&stDateStart=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDateStart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&stDateEnd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDateEnd\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&page=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m     headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthority\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinance.naver.com\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     28\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\u001b[39m\u001b[38;5;124m'\u001b[39m}\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DatetimeIndex' object is not callable"
     ]
    }
   ],
   "source": [
    "# NNC(NaverNewsCrawling)\n",
    "import time\n",
    "import datetime\n",
    "import requests, os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "date_range = pd.date_range('2013-01-01', '2023-08-31', freq='W')\n",
    "date_role = date_range[::111]\n",
    "date_range = pd.date_range('2013-01-01', '2023-08-31', freq='W')\n",
    "df = pd.DataFrame(columns =['신문사', '제목', '내용', '날짜'])\n",
    "\n",
    "\n",
    "for date in tqdm(date_range):\n",
    "    DateStart = date.strftime('%Y-%m-%d')\n",
    "    DateEnd = (date+datetime.timedelta(7)).strftime('%Y-%m-%d')\n",
    "    last_url = f\"https://finance.naver.com/news/news_search.naver?rcdate=&q=%B1%DD%B8%AE&x=20&y=14&sm=all.basic&pd=4&stDateStart={DateStart}&stDateEnd={DateEnd}&page=1\"\n",
    "    headers = {'authority' : 'finance.naver.com',\n",
    "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'}\n",
    "    response = requests.get(last_url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content)\n",
    "    last_page = soup.select('.pgRR a')[0]['href'].split('=')[-1] # =기준 split으로 수정\n",
    "    print(last_page)\n",
    "    for i in tqdm(range(1, int(last_page)+1)):   # 여기서 다양한 최종페이지까지 설정\n",
    "        news_url = f\"https://finance.naver.com/news/news_search.naver?rcdate=&q=%B1%DD%B8%AE&x=20&y=14&sm=all.basic&pd=4&stDateStart={DateStart}&stDateEnd={DateEnd}&page={i}\"\n",
    "        headers = {'authority' : 'finance.naver.com',\n",
    "                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'}\n",
    "        response = requests.get(news_url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content)\n",
    "        news = soup.select('.thumb a' )\n",
    "        magazine = soup.select('.articleSummary .press')\n",
    "        date = soup.select('.articleSummary .wdate')\n",
    "\n",
    "        news_link = []\n",
    "        magazine_name = []\n",
    "        dates = []\n",
    "        for i in range(len(news)):\n",
    "            news_link.append('https://finance.naver.com' + news[i].attrs['href'].replace('amp;', ''))\n",
    "            magazine_name.append(magazine[i].text)\n",
    "            dates.append(date[i])\n",
    "\n",
    "        total = []\n",
    "        for index, j in enumerate(news_link):\n",
    "            news_resp = requests.get(j, headers=headers)\n",
    "            news_soup = BeautifulSoup(news_resp.content)\n",
    "            try:\n",
    "                title = news_soup.select('.article_info h3')[0].text.strip()\n",
    "                content = news_soup.select('#content')[-1].text.strip()\n",
    "            except:\n",
    "                print(j)\n",
    "                continue\n",
    "            total.append([magazine_name[index],title, content, date[index].text.lstrip()[:10]])\n",
    "        \n",
    "        df_temp = pd.DataFrame(total, columns = ['신문사', '제목', '내용', '날짜'])\n",
    "        df = pd.concat([df, df_temp], ignore_index = True)\n",
    "    df.to_csv(f'{DateStart}_{DateEnd}.csv', encoding='utf-8')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>신문사</th>\n",
       "      <th>제목</th>\n",
       "      <th>내용</th>\n",
       "      <th>날짜</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>세계일보</td>\n",
       "      <td>자영업자 신용대출 ‘저금리 대환’</td>\n",
       "      <td>코로나 기간내 고금리 대출자31일부터 최대 2000만원까지 신종 코로나바이러스 감염...</td>\n",
       "      <td>2023-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>전세가구 이자비용 67% 급증… 월 20만원 첫 돌파</td>\n",
       "      <td>2023년 2분기 21만4000원 기록1년 반 만에 두 배 넘게 뛰어자가가구와 격차...</td>\n",
       "      <td>2023-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>'잭슨홀 쇼크' 피했지만…'금리 딜레마' 여전한 한은</td>\n",
       "      <td>■우리 경제 여파는강도 낮췄지만 美 초긴축 여전유가상승 등으로 물가도 불안금리인하 ...</td>\n",
       "      <td>2023-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>세계일보</td>\n",
       "      <td>은행권 ‘부산 주 금고’ 잡기 ‘군침’… “지역 기여도 높여 평가해야”</td>\n",
       "      <td>지자체 등 70% 내년 계약 만료13곳 모두 부산은행 주 금고 거래시중은행 견제·도...</td>\n",
       "      <td>2023-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>서울경제</td>\n",
       "      <td>[단독] 슈퍼리치 놀이터라고?...10만원으로도 투자가능한 국채 나온다</td>\n",
       "      <td>서민 장기저축 지원 목적10년·20년 등 장기물로 출시만기보유시 분리과세·가산금리 ...</td>\n",
       "      <td>2023-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>2609</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>중국발 경기 불안에…한은, 24일 기준금리 5연속 동결할 듯</td>\n",
       "      <td>전문가 \"2%p 한미 금리차·가계대출 증가에도 경기 우려로 못 올려\" \"한은, 올해...</td>\n",
       "      <td>2023-08-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>2610</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>G2발 금융위기 확산…코스피 2,400까지 떨어지나</td>\n",
       "      <td>위안화·원화 약세에 외국인 매도압력…\"환율 1,300원대 후반 가능성\"\"중국 부동산...</td>\n",
       "      <td>2023-08-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>2611</td>\n",
       "      <td>YTN</td>\n",
       "      <td>문제 생기면 '은행 탓'…정부 가계빚 정책 엇박자 비판↑</td>\n",
       "      <td>금리 인하 옥죌 때는 언제고… 가계빚 늘자 또다시 은행권에 관리 주문50년 만기 주...</td>\n",
       "      <td>2023-08-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>2612</td>\n",
       "      <td>노컷뉴스</td>\n",
       "      <td>뉴욕증시, 엔비디아 실적 발표·연준 잭슨홀 컨퍼런스에 초점</td>\n",
       "      <td>[파이낸셜뉴스]   뉴욕증시 흐름을 좌우할 엔비디아 분기실적 발표가 23일(현지시간...</td>\n",
       "      <td>2023-08-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>2613</td>\n",
       "      <td>파이낸셜뉴스</td>\n",
       "      <td>비트코인, 이틀 만에 10% 이상 폭락</td>\n",
       "      <td>연합뉴스  추가 통화긴축 가능성이 위험자산 투자심리를 위축스페이스X 보유 비트코인 ...</td>\n",
       "      <td>2023-08-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2614 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      신문사                                       제목  \\\n",
       "0              0    세계일보                        자영업자 신용대출 ‘저금리 대환’   \n",
       "1              1    경향신문             전세가구 이자비용 67% 급증… 월 20만원 첫 돌파   \n",
       "2              2    경향신문             '잭슨홀 쇼크' 피했지만…'금리 딜레마' 여전한 한은   \n",
       "3              3    세계일보   은행권 ‘부산 주 금고’ 잡기 ‘군침’… “지역 기여도 높여 평가해야”   \n",
       "4              4    서울경제   [단독] 슈퍼리치 놀이터라고?...10만원으로도 투자가능한 국채 나온다   \n",
       "...          ...      ...                                      ...   \n",
       "2609        2609    연합뉴스         중국발 경기 불안에…한은, 24일 기준금리 5연속 동결할 듯   \n",
       "2610        2610    연합뉴스              G2발 금융위기 확산…코스피 2,400까지 떨어지나   \n",
       "2611        2611     YTN           문제 생기면 '은행 탓'…정부 가계빚 정책 엇박자 비판↑   \n",
       "2612        2612    노컷뉴스          뉴욕증시, 엔비디아 실적 발표·연준 잭슨홀 컨퍼런스에 초점   \n",
       "2613        2613  파이낸셜뉴스                     비트코인, 이틀 만에 10% 이상 폭락   \n",
       "\n",
       "                                                     내용          날짜  \n",
       "0     코로나 기간내 고금리 대출자31일부터 최대 2000만원까지 신종 코로나바이러스 감염...  2023-08-27  \n",
       "1     2023년 2분기 21만4000원 기록1년 반 만에 두 배 넘게 뛰어자가가구와 격차...  2023-08-27  \n",
       "2     ■우리 경제 여파는강도 낮췄지만 美 초긴축 여전유가상승 등으로 물가도 불안금리인하 ...  2023-08-27  \n",
       "3     지자체 등 70% 내년 계약 만료13곳 모두 부산은행 주 금고 거래시중은행 견제·도...  2023-08-27  \n",
       "4     서민 장기저축 지원 목적10년·20년 등 장기물로 출시만기보유시 분리과세·가산금리 ...  2023-08-27  \n",
       "...                                                 ...         ...  \n",
       "2609  전문가 \"2%p 한미 금리차·가계대출 증가에도 경기 우려로 못 올려\" \"한은, 올해...  2023-08-20  \n",
       "2610  위안화·원화 약세에 외국인 매도압력…\"환율 1,300원대 후반 가능성\"\"중국 부동산...  2023-08-20  \n",
       "2611  금리 인하 옥죌 때는 언제고… 가계빚 늘자 또다시 은행권에 관리 주문50년 만기 주...  2023-08-20  \n",
       "2612  [파이낸셜뉴스]   뉴욕증시 흐름을 좌우할 엔비디아 분기실적 발표가 23일(현지시간...  2023-08-20  \n",
       "2613  연합뉴스  추가 통화긴축 가능성이 위험자산 투자심리를 위축스페이스X 보유 비트코인 ...  2023-08-20  \n",
       "\n",
       "[2614 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "news = pd.read_csv('2023-08-20_2023-08-27.csv')\n",
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'141'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "today = datetime.datetime.today()\n",
    "\n",
    "DateStart = (today-datetime.timedelta(7)).strftime('%Y-%m-%d')\n",
    "DateEnd = today.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "last_url = f\"https://finance.naver.com/news/news_search.naver?rcdate=&q=%B1%DD%B8%AE&x=20&y=14&sm=all.basic&pd=4&stDateStart={DateStart}&stDateEnd={DateEnd}&page=1\"\n",
    "headers = {'authority' : 'finance.naver.com',\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'}\n",
    "response = requests.get(last_url, headers=headers)\n",
    "soup = BeautifulSoup(response.content)\n",
    "news = soup.select('.pgRR a')[0]['href'][-3:]\n",
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채권 기사\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29865f05af80384af78d9233101596088e9d9771dcfe0a2d252f1a59aee54b06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
